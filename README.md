# I310D-HCDS-Assignment-2-Data-Bias

# Overview 
Using the Perspective API client to score the toxicity of each comment, I wish to compare the toxicity scores of comments containing insults towards hispanic people and white people. 

Hypothesis: Perspective API will assign a higher toxicity score to insulting comments towards white people than those left towards hispanic people.

To compare the toxicity scores given to insulting comments by Perspective API, parallel comments towards white and hispanic people will be created. 

For example, one comment may read "WHITE PEOPLE SUCK" while the other states "HISPANIC PEOPLE SUCK". The toxicity scores from these comments will be found then compared. 15 insulting comments towards white people and 15 insulting comments towards hispanic people will be analyzed. Therefore, our total sample size will be 30 comments. 

After initial comparisons, a threshold will be developed to categorize the insulting comments as toxic or severely-toxic. 

Lists were created to store the toxicity scores given to insulting comments of both groups. The average of these scores will now be calculated to give us an idea if the Perspective AI gives an overall higher toxicity score to insulting comments towards white people than those of hispanic people. 

As seen by the averages of toxicity scores given to insulting comments of both groups, the Perspective AI assigned higher toxicity scores to insulting comments made towards white people than those left towards hispanic people. 

This bar chart compares the toxicity score of insulting comments given to hispanic people and white people. As shown, the majority of comments received a higher toxicity score when directed towards white people. However, both Comment 4 and Comment 11 disrupted this trend as the insulting comment directed towards hispanic people received a higher toxicity score. 

Now that initial comparisons have been made, the insulting comments will be labeled as toxic or extremely-toxic based on their toxicity score. These labels were chosen due to the default negative nature of the comments. If a comment received a toxicity score between 0 and 0.5, it is considered toxic. If a comment received a toxicity score greater than 0.5, it is considered extremely toxic. 

This bar graph compares the number of comments labeled as toxic and extremely toxic. As seen the in the graph, there were more insulting comments considered to be extremely toxic than toxic. There were 9 toxic comments and 21 extremely toxic comments.

# Results
